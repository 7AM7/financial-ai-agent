# AI-Powered Financial Data System

> Transform heterogeneous financial data into unified insights with AI-powered natural language querying.

---

## ğŸ¯ The Business Problem

**Challenge**: Companies use multiple accounting platforms (QuickBooks, Rootfi, etc.) that generate data in different formats with different structures. Financial teams struggle to:
- Consolidate reports across systems
- Answer ad-hoc questions quickly
- Identify trends without manual spreadsheet work
- Make data-driven decisions in real-time

**Solution**: An AI-powered system that:
- âœ… **Unifies** diverse financial data sources into a single database
- âœ… **Queries** data using natural language (no SQL knowledge needed)
- âœ… **Visualizes** key metrics in an interactive dashboard
- âœ… **Adapts** dashboard layout based on user requests (e.g., "swap revenue and profit boxes")

**Real-World Example**:
- CFO asks: *"What was our Q1 profit compared to Q2?"*
- System: Understands query â†’ Generates SQL â†’ Validate SQL query â†’Returns answer with context
- User says: *"Switch the total profit and total revenue positions"*
- Dashboard: Instantly swaps component positions

---

## ğŸš€ Quick Start

**One command to run everything:**

```bash
# 1. Setup environment
cp .env.example .env
# Edit .env with your OpenAI/Azure OpenAI credentials

# 2. Start the system
make start
```

**Access the system:**
- ğŸŒ **Dashboard**: http://localhost:3000
- ğŸ”§ **API**: http://localhost:8000
- ğŸ“š **API Docs**: http://localhost:8000/docs

**Key Commands:**
```bash
./start.sh       # Start everything (postgres â†’ data pipeline â†’ backend â†’ frontend)
make stop        # Stop all services
make restart     # Restart with fresh data
make logs        # View logs
```

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Financial Data (QuickBooks + Rootfi JSON)                  â”‚
â”‚  â€¢ Different formats, dates, hierarchies                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Pipeline (ELT)                   ğŸ“– data_pipeline/    â”‚
â”‚  â€¢ Extract: Parse both JSON formats                          â”‚
â”‚  â€¢ Transform: Normalize & categorize                         â”‚
â”‚  â€¢ Load: Star schema in PostgreSQL                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL Database                                         â”‚
â”‚  â€¢ Unified star schema (fact_financials + dimensions)        â”‚
â”‚  â€¢ Jan 2020 - Aug 2025 (66 months of data)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend API (FastAPI + LangGraph)     ğŸ“– backend/          â”‚
â”‚  â€¢ REST endpoints for dashboard data                         â”‚
â”‚  â€¢ AI Agent: Natural language â†’ SQL â†’ Response              â”‚
â”‚  â€¢ Supports OpenAI and Azure OpenAI                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend (Next.js + CopilotKit)       ğŸ“– frontend/         â”‚
â”‚  â€¢ Interactive dashboard with charts                         â”‚
â”‚  â€¢ AI chatbot for natural language queries                   â”‚
â”‚  â€¢ Component swapping: "swap revenue and profit boxes"       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Key Features

### 1. Natural Language Queries
Ask questions in plain English:
- *"What was total revenue in Q1 2024?"*
- *"Show me top expense categories"*
- *"Compare Q1 and Q2 performance"*

### 2. Interactive Dashboard
- Real-time financial charts (P&L, Revenue, Expenses)
- Key metrics with growth indicators
- **Component Swapping**: Tell the AI to rearrange dashboard widgets
  - *"Switch the total profit with total revenue"*
  - *"Move the expenses chart to the top"*

### 3. Intelligent AI Agent
- LangGraph workflow with error recovery
- Automatically fixes and retries failed queries
- Streaming responses (see agent thinking in real-time)

### 4. Unified Data Model
- Handles QuickBooks (column-based, 1.1MB)
- Handles Rootfi (period-based, 485KB)
- Star schema optimized for fast analytics (<100ms queries)

---

## âš™ï¸ Configuration

### 1. Create Environment File
```bash
cp .env.example .env
```

### 2. Add LLM Credentials

**Option A: Azure OpenAI** (Recommended)
```env
MODEL=gpt-4o-mini
MODEL_PROVIDER=azure_openai
API_KEY=your_azure_api_key
AZURE_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_DEPLOYMENT=gpt-4o-mini
OPENAI_API_VERSION=2025-03-01-preview
```

**Option B: OpenAI**
```env
MODEL=gpt-4o-mini
MODEL_PROVIDER=openai
API_KEY=sk-your_openai_api_key
```

---

## ğŸ”§ Component Documentation

Each component has its own detailed README:

| Component | Purpose | Documentation |
|-----------|---------|---------------|
| **Data Pipeline** | ELT pipeline: extracts, transforms, loads financial data | [ğŸ“– data_pipeline/README.md](data_pipeline/README.md) |
| **Backend API** | FastAPI + LangGraph SQL agent | [ğŸ“– backend/README.md](backend/README.md) |
| **Frontend** | Next.js dashboard + AI chatbot | [ğŸ“– frontend/README.md](frontend/README.md) |

**Technical Reports:**
- [Data Structure Analysis](data_pipeline/docs/DATA_REPORT.md) - Deep dive into JSON formats
- [Pipeline Architecture](data_pipeline/docs/TECHNICAL_REPORT.md) - ELT design decisions
- [Backend Agent Design](backend/docs/BACKEND_REPORT.md) - LangGraph workflow
- [Frontend Integration](frontend/docs/FRONTEND_REPORT.md) - CopilotKit setup

---

## âš¡ Critical: Startup Order

**The system has 3 components that MUST start in this order:**

```
1. PostgreSQL          (Docker container)
2. Data Pipeline       (Separate Python project - NOT in Docker)
3. Backend + Frontend  (Docker containers)
```

**Why this matters:**
- âŒ Backend will CRASH if database has no data
- âš ï¸ Data pipeline is a SEPARATE Python project in `./data_pipeline/`
- âœ… Use `make start` - it handles everything automatically

**Manual startup (if needed):**
```bash
# 1. Start database
docker compose up -d postgres

# 2. Run data pipeline (SEPARATE project!)
cd data_pipeline
source venv/bin/activate  # or create venv if first time
python main.py init && python main.py run
cd ..

# 3. Start backend and frontend
docker compose up -d backend frontend
```

---

## ğŸ› Troubleshooting

### "fetch failed" in Chatbot?
**Cause**: Wrong URLs in frontend configuration

**Fix**:
```bash
# Check frontend/.env.local has correct URLs:
cat frontend/.env.local

# Should contain:
# REMOTE_ACTION_URL=http://backend:8000/copilotkit  (server-side)
# NEXT_PUBLIC_API_URL=http://localhost:8000          (client-side)

# Restart frontend
docker compose restart frontend
```

### Backend Not Connecting to Database?
```bash
# Check PostgreSQL is running
docker ps | grep postgres

# Verify data was loaded
docker exec -it financial-postgres \
  psql -U postgres -d financial_data -c "SELECT COUNT(*) FROM fact_financials;"
# Should return a count > 0

# If no data, re-run pipeline
cd data_pipeline && python main.py run && cd ..
```

### Port Already in Use?
```bash
# Check what's using ports
lsof -i :3000  # Frontend
lsof -i :8000  # Backend
lsof -i :5432  # PostgreSQL

# Stop conflicting services or change ports in docker-compose.yml
```

---

## ğŸ“Š Example Usage

### Dashboard Interactions

**Ask questions:**
- *"What was total profit in Q1 2024?"*
- *"Show me revenue trends over time"*
- *"Which expense category had the highest increase?"*

**Rearrange components:**
- *"Swap the revenue and profit boxes"*
- *"Switch the total profit with total revenue"*
- *"Move the chart to the top"*

### REST API

```bash
# Get dashboard overview
curl http://localhost:8000/api/dashboard/overview

# Ask natural language question
curl -X POST http://localhost:8000/api/chat/query \
  -H "Content-Type: application/json" \
  -d '{"question": "What was total revenue in Q1 2024?"}'
```

---

## ğŸ› ï¸ Technology Stack

| Layer | Technologies |
|-------|-------------|
| **Data Pipeline** | Python, SQLAlchemy, PostgreSQL, Pydantic |
| **Backend** | FastAPI, LangGraph, LangChain, CopilotKit |
| **LLM** | OpenAI GPT-4o-mini or Azure OpenAI |
| **Database** | PostgreSQL 16 (Star Schema) |
| **Frontend** | Next.js 15, React 19, TypeScript, CopilotKit |
| **Infrastructure** | Docker, Docker Compose |

---

## ğŸ“ Project Structure

```
financial-ai-agent/
â”œâ”€â”€ README.md              # â† You are here
â”œâ”€â”€ start.sh               # ğŸš€ One-command startup
â”œâ”€â”€ Makefile               # Convenient commands
â”œâ”€â”€ docker-compose.yml     # Docker orchestration
â”œâ”€â”€ .env.example           # Configuration template
â”‚
â”œâ”€â”€ data_pipeline/         # ğŸ“– ELT Pipeline
â”‚   â”œâ”€â”€ README.md          # Pipeline documentation
â”‚   â”œâ”€â”€ data/              # Source JSON files
â”‚   â”œâ”€â”€ src/               # Python ETL code
â”‚   â””â”€â”€ docs/              # Technical reports
â”‚
â”œâ”€â”€ backend/               # ğŸ“– FastAPI + LangGraph
â”‚   â”œâ”€â”€ README.md          # Backend documentation
â”‚   â”œâ”€â”€ src/               # API and agent code
â”‚   â”œâ”€â”€ tests/             # Unit + integration tests
â”‚   â””â”€â”€ docs/              # Architecture report
â”‚
â””â”€â”€ frontend/              # ğŸ“– Next.js + CopilotKit
    â”œâ”€â”€ README.md          # Frontend documentation
    â”œâ”€â”€ app/               # Next.js routes
    â”œâ”€â”€ components/        # React components
    â””â”€â”€ docs/              # Integration report
```

---

## ğŸ¯ What This Demonstrates

âœ… **AI Integration** - Natural language querying with LangGraph agents
âœ… **Data Engineering** - ELT pipeline with star schema design
âœ… **Backend Architecture** - FastAPI + LangGraph + CopilotKit streaming
âœ… **Frontend Development** - Next.js with AI chatbot + component swapping
âœ… **Production Readiness** - Docker, tests, monitoring, documentation

### Requirements Met
- âœ… Integrated heterogeneous financial data (QuickBooks + Rootfi)
- âœ… Natural language querying with AI agent
- âœ… RESTful API with OpenAPI documentation
- âœ… Interactive dashboard with AI capabilities
- âœ… Clean architecture with comprehensive docs
- âœ… Docker containerization
- âœ… Test coverage (unit + integration)

---

## ğŸ“ Support

**Issues?** Check troubleshooting section above or component READMEs:
- [Data Pipeline README](data_pipeline/README.md)
- [Backend README](backend/README.md)
- [Frontend README](frontend/README.md)

---

**Built by AM7** | AI-Powered Financial Data System
